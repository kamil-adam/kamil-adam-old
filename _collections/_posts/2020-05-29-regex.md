---
title:    'Użycie wyrażeń regularnych w języku Scala'
author:   kamil-adam
category: scala-native
tags:     parser lexer IR regex resentiment
langs:    lua scala
tools:    llvm
---


Nie zawsze,
gdy chcemy dokonać analizy jakagoś tekstu z danymi potrzebyjemy [analizotora składniowego].
Czasem wystarczy sam [analizator leksykalny]
lub wręcz same wyrażenia regularne zwane popularnie regex lub regexp.

https://docs.scala-lang.org/pl/tutorials/tour/regular-expression-patterns.html.html


## Przykład na przykład
W poniższym przykładzie poddamy analizie kod źródłowy języka lua skompilowany za pomocą kompilatora LLVM 
do języka symbolicznego IR.
Język symboliczny wygenerowany przez kompilator **[LLVM]** posiada prostą skadnie i ujednolicone formatowanie co pomaga w analizie.

Sercem programu jest plik `Token`:
```scala
package pl.writeonly.re.shared.llvm.regex

import scalaz.Scalaz._

case class Instruction(token: String) extends Ordered[Instruction] {

  def compare(that: Instruction): Int = this.token compare that.token

  def show: String = token
}

object Instruction {
  private val r = """^  (%\d+ = )?(\w+).*$""".r

  def parseLines(xs: List[String]): List[Instruction] = xs
    .map(parseLine)
    .flatMap(_.toList)

  private[regex] def parseLine(input: String): Option[Instruction] = input match {
    case r(_, token) => token |> (Instruction(_)) |> Option.apply
    case _           => Option.empty[Instruction]
  }
}
```
A sercem pliku `Token` jest linia zawierająca wyrażenie regularne.
Wyszukunie ono wszystkie rozkazy 



Będziemy chcieli ustalić, które z rozkazów języka symbolicznego IR wytępuję najczęściej.


W tym celu sparsowaną listę rozkazów zagregujemy.
Wynikiem agrekacji będzie tablica asocjacyjna `(NAZWA_ROZKAZU -> ILOŚĆ_WYSTĄPIEŃ)`.  
Następnie tablicę asocjacyjną zamienimy na listę posortowaną pod względen ilości wystąpień.
Tak przygotowane informacje wyświetlimy ograniczając się do tych rozkazów które występują najczęściej, czyli powyżej 5000 razy.
Liczba wybrana całkowicie heurystycznie


https://github.com/writeonly/lua



https://github.com/writeonly/lua-llvm



https://clang.llvm.org/docs/CommandGuide/clang.html





Prosty Skrypt który analizuje pliki `ll`.
Fragment klasy `Glue`
```scala
    val levels = List("0", "1", "2", "3", "fast", "g", "s", "z")

    val path = "../lua-llvm/O"
    val tables = levels
      .map(path + _)
      .map(AggregateTable.apply)
```

Uruchomienie
```bash
sbt clean re/run
```

Wyniki
Wynik to :
```bash
[info, pl.writeonly.re.shared.llvm.regex.Glue] FILTRED DATAS
[info, pl.writeonly.re.shared.llvm.regex.Glue] ../lua-llvm/O0, 42, (load, 42957), (store, 16905), (getelementptr, 16102), (br, 13630), (alloca, 9587), (call, 8565), (icmp, 5680), (bitcast, 5330)
[info, pl.writeonly.re.shared.llvm.regex.Glue] ../lua-llvm/O1, 43, (br, 10025), (getelementptr, 9553), (load, 8920), (tail, 6199), (icmp, 5300)
[info, pl.writeonly.re.shared.llvm.regex.Glue] ../lua-llvm/O2, 46, (getelementptr, 25618), (load, 24154), (br, 23360), (icmp, 12548), (store, 10517), (phi, 7638), (bitcast, 7547), (call, 6138), (tail, 5144)
[info, pl.writeonly.re.shared.llvm.regex.Glue] ../lua-llvm/O3, 46, (getelementptr, 28870), (load, 27299), (br, 26251), (icmp, 14097), (store, 11810), (phi, 8800), (bitcast, 8536), (call, 6353), (tail, 5361)
[info, pl.writeonly.re.shared.llvm.regex.Glue] ../lua-llvm/Ofast, 47, (getelementptr, 28870), (load, 27299), (br, 26247), (icmp, 14097), (store, 11810), (phi, 8800), (bitcast, 8536), (call, 6346), (tail, 5356)
[info, pl.writeonly.re.shared.llvm.regex.Glue] ../lua-llvm/Og, 43, (br, 10025), (getelementptr, 9553), (load, 8920), (tail, 6199), (icmp, 5300)
[info, pl.writeonly.re.shared.llvm.regex.Glue] ../lua-llvm/Os, 46, (getelementptr, 11929), (br, 11223), (load, 11109), (icmp, 5856), (store, 5769)
[info, pl.writeonly.re.shared.llvm.regex.Glue] ../lua-llvm/Oz, 44, (br, 10070), (getelementptr, 9448), (load, 8956), (tail, 5065)
```



## Wnioski

https://llvm.org/docs/LangRef.html#phi-instruction


W nieoptymalizowanym kodzie dominują odczyty (`load`) i zapisy (`store`)

* `load` - Instrukcja „load” służy do odczytu z pamięci.
* `store` - Instrukcja „store” służy do zapisu do pamięci.

W pozostałych na zmianę `getelementptr` i skoki `br`

* `getelementptr` - Instrukcja „getelementptr” służy do uzyskania adresu podelementu zagregowanej struktury danych. 
Wykonuje tylko obliczenia adresu i nie uzyskuje dostępu do pamięci. 
Instrukcja może być również używana do obliczania wektora takich adresów.
* `br` Instrukcja „br” jest używana do spowodowania przeniesienia przepływu sterowania do innego bloku podstawowego w bieżącej funkcji. 
Istnieją dwie formy tej instrukcji, odpowiadające warunkowej gałęzi i bezwarunkowej gałęzi.
* `alloca` - Instrukcja „alloca” przydziela pamięć na ramce stosu aktualnie wykonywanej funkcji, 
która ma zostać automatycznie zwolniona, 
gdy ta funkcja wróci do wywołującego. 
Obiekt jest zawsze przydzielany w przestrzeni adresowej dla alokacji wskazanych w polu danych.
* `call` - Instrukcja „wywołanie” reprezentuje proste wywołanie funkcji.
* `icmp` - Instrukcja „icmp” zwraca wartość boolowską lub wektor wartości logicznych w oparciu o porównanie dwóch operandów: 
liczby całkowitej, liczby całkowitej, wskaźnika lub wektora wskaźnika.
* `bitcast` - Instrukcja „bitcast” konwertuje wartość na typ ty2 bez zmiany bitów.
* `phi` - Instrukcja „phi” służy do implementacji węzła φ na wykresie SSA reprezentującego funkcję. 
* `tail` - Nie jest rozkazem ale opcjonalnym znacznikiem wskazujcym, że optymalizatory powinny wykonywać optymalizację wywołań ogonowych. 
Znacznik ogona jest wskazówką, którą można zignorować.

Pełne omówienie rozkazów LLVM można znaleść pod adresem https://llvm.org/docs/LangRef.html


https://llvm.org/docs/GetElementPtr.html

## Wnioski

Widać wyraźnie że łączenie jakiejkolwiek optymalizacji znacząco zmienia kod języka symbolicznego.


[analizator leksykalny]:    /tags/lexer
[analizotora składniowego]: /tags/parser
[regex]:                    /tags/regex

